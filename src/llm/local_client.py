# Optional: local LLM (Transformers/Ollama) implementation.
# Not needed for the MVP; kept as a seam for later.
